{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module adverse - analyse de qualité de l'anonymisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "# Classic modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time as time\n",
    "import numpy as np\n",
    "\n",
    "#from anonympy.pandas import dfAnonymizer\n",
    "\n",
    "from pycanon import anonymity, report\n",
    "\n",
    "# Functions\n",
    "from utils.exploration import explo, clean, drop\n",
    "from utils.correlation import categorical_comparison, p_vals_correction, numerical_correlation\n",
    "from utils.tools import col_set\n",
    "from utils.outliers import identify_outliers, explore_outliers, identify_num_outliers, cluster\n",
    "from utils.stats import categorical_loss, numerical_loss, plot_info_loss, target_loss\n",
    "from utils.inference import Infer_Model, compare_models\n",
    "\n",
    "from utils.ano_correc import all_local_aggregation, get_diversities, less_diverse_groups, get_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your dataset\n",
    "path_to_ano = \"data/ano.csv\"\n",
    "path_to_original = \"data/ori.csv\"\n",
    "path_to_val = \"data/control.csv\"\n",
    "\n",
    "# Columns you want to study\n",
    "cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "cols_df = pd.read_csv(\n",
    "    path_to_original,\n",
    "    usecols = cols,\n",
    "\n",
    "    # Uncomment the following lines as needed\n",
    "\n",
    "    #encoding=\"utf-8\",\n",
    "    sep=\",\",\n",
    "    #lineterminator=\"\\n\",\n",
    "    #header=0,\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_df = pd.read_csv(path_to_ano,\n",
    "                     usecols=cols)\n",
    "\n",
    "val_set = pd.read_csv(path_to_val,\n",
    "                            usecols = cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target =''\n",
    "QI = []\n",
    "SA = [target]\n",
    "\n",
    "# The following must include the target column name in the appropriate list\n",
    "num_cols = []\n",
    "cat_cols = []\n",
    "\n",
    "# This value represents 0.1 percent of the total dataframe size\n",
    "n_1_perc = int((len(cols_df)*0.001)//1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche adverse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non individualisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers\n",
    "\n",
    "ano_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des outliers en terme de donnée catégorielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a PCA with n_components = 2, this allows us to visualize the potential outliers based on categorical features\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "X = enc.fit_transform(ano_df[QI]).toarray()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "res = pd.DataFrame(pca.fit_transform(X),columns=['PC1','PC2']) \n",
    "\n",
    "plt.scatter(res['PC1'], res['PC2'], c=\"tomato\")\n",
    "plt.title(\"Principal Components repartition(n=2)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des outliers en terme de donnée numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a scatter plot, this allows us to visualize the potential outliers based on numerical features\n",
    "identify_num_outliers(ano_df, num_cols, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des doubles outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a cluster analysis, this allows us to visualize the potential outliers based on both the numerical and categorical feature\n",
    "# This is time consuming and therefore commented out for faster execution time\n",
    "\n",
    "#cluster(temp, n_clusters = 100, cat_cols = cat_cols)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non inférence :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier scénario d'attaque : prédire un attribut d'un individu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This studies whether or not an attacker with the anonymized dataset is more or less capable of predicting an individual's\n",
    "# attribute than if they had the original dataset\n",
    "\n",
    "# For each variable, this considers it as the target variable. By training a prediction model (classification or regresion)\n",
    "# on both the anonymized and original data, this allows us to compare both of these models' performance\n",
    "\n",
    "res = pd.DataFrame(columns = [\"Target\", \"Score de performance de la prédiction\", \"Delta in score\"])\n",
    "\n",
    "for x in ano_df.columns :\n",
    "    target = str(x) \n",
    "    model = Infer_Model(ano_df, cat_cols=cat_cols, num_cols = num_cols, target = target)\n",
    "    before_model = Infer_Model(cols_df, cat_cols=cat_cols, num_cols = num_cols, target = target)\n",
    "    val_model = Infer_Model(val_set, cat_cols=cat_cols, num_cols = num_cols, target = target)\n",
    "\n",
    "    model.prep_data()\n",
    "    before_model.prep_data()\n",
    "    val_model.prep_data()\n",
    "\n",
    "    model.df = model.df.align(before_model.df, join='right', axis=1, fill_value=0)[0]\n",
    "    val_model.df = val_model.df.align(before_model.df, join='right', axis=1, fill_value=0)[0]\n",
    "\n",
    "    x_train, x_test, y_train, y_test =  model.split()\n",
    "    pred = model.train_model(x_train, x_test, y_train, y_test)\n",
    "    x_train, x_test, y_train, y_test =  before_model.split()\n",
    "    pred_original = before_model.train_model(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    new_cols =list(val_model.df.columns)\n",
    "    new_cols.remove(target)\n",
    "    _, model_score, delta = compare_models(pred, pred_original, val_model.df[new_cols], val_model.df[target], print_bool=False)\n",
    "    res.loc[len(res)] = [target, model_score, delta]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.plot.bar(x='Target', stacked=True, color=['tomato','lightseagreen'], figsize=(7,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième scénario d'attaque : ré-entrainer un modèle en connaissant un certain nombre de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This studies whether or not an attacker with access to a subset of the original dataset is capable of training a high\n",
    "# performing prediction model\n",
    "\n",
    "attack_df = cols_df[cols].copy()\n",
    "\n",
    "attacker_set = attack_df.sample(frac=0.3)\n",
    "attack_df.drop(index = attacker_set.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates and trains the prediction model\n",
    "\n",
    "attack_model = Infer_Model(attacker_set, cat_cols=cat_cols, num_cols = num_cols, target = target)\n",
    "attack_model.prep_data()\n",
    "x_train, x_test, y_train, y_test =  attack_model.split()\n",
    "attack_pred = attack_model.train_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now compare the model's performance to an anonymized version of the subset the attacker could have\n",
    "\n",
    "attacker_ano = all_local_aggregation(attack_df.copy(),k=n_1_perc, variables = QI, method = 'regroup_with_smallest')\n",
    "\n",
    "for x in [attacker_ano, attack_df]:\n",
    "    val_model = Infer_Model(x, cat_cols=cat_cols, num_cols = num_cols, target = target)\n",
    "    val_model.prep_data()\n",
    "    val_model.df = val_model.df.align(attack_model.df, join='right', axis=1, fill_value=0)[0]\n",
    "    new_cols =list(val_model.df.columns)\n",
    "    new_cols.remove(target)\n",
    "    print(attack_pred.score(val_model.df[new_cols], val_model.df[target]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité de la donnée statistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perte d'information - donnée catégorielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_loss(cols_df, ano_df, QI)\n",
    "\n",
    "plot_info_loss(cols_df,ano_df, cat_cols)\n",
    "\n",
    "target_loss(cols_df, ano_df, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perte d'information - donnée numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_loss(cols_df, ano_df, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualité et évolution de l'anonymisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate k for k-anonymity for the anonymized and original data:\n",
    "k = anonymity.k_anonymity(ano_df, QI)\n",
    "\n",
    "print(\"According to the anonymity pycanon module, the k-anonymity post-anonymization is {}\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_og = anonymity.k_anonymity(cols_df, QI)\n",
    "\n",
    "#print(\"According to the anonymity pycanon module, the k-anonymity pre-anonymization is {}\".format(k_og))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate l for l-diversity for the anonymized and original data:\n",
    "\n",
    "cols = list(ano_df.columns)\n",
    "for x in cols :\n",
    "    QI = list(ano_df.columns)\n",
    "    QI.remove(x)\n",
    "    n = np.mean(ano_df.groupby(QI)[x].count())\n",
    "    l = get_l(ano_df, QI, x)\n",
    "    print(\"For {} as QIs and {} as the target, the l-diversity is of {} throughout {} values on average.\".format(QI, x, l, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(cols_df.columns)\n",
    "for x in cols :\n",
    "    QI = list(cols_df.columns)\n",
    "    QI.remove(x)\n",
    "    n = np.mean(cols_df.groupby(QI)[x].count())\n",
    "    l = get_l(cols_df, QI, x)\n",
    "    print(\"For {} as QIs and {} as the target, the l-diversity is of {} throughout {} values on average.\".format(QI, x, l, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the anonymity report:\n",
    "\n",
    "ano_df.reset_index(inplace=True, drop=True)\n",
    "report.print_report(ano_df, QI, SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the computational time\n",
    "\n",
    "t1 = time.time()\n",
    "elapsed_time = t1-t0\n",
    "print(\"The computational time for the adversary module is {}\".format(elapsed_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
