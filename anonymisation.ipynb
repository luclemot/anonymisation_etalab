{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymisation du jeu de données des équidés"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "# Classic modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Anonymization modules\n",
    "from anonymizer.anonymity import get_k\n",
    "from anonymizer.anonymity import local_aggregation\n",
    "\n",
    "#from anonympy.pandas import dfAnonymizer\n",
    "\n",
    "from pycanon import anonymity, report\n",
    "\n",
    "# Functions\n",
    "from utils.exploration import explo, clean, drop\n",
    "from utils.correlation import categorical_comparison, p_vals_correction, numerical_correlation\n",
    "from utils.tools import col_set\n",
    "from utils.outliers import identify_outliers, identify_num_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your dataset\n",
    "path = \"\"\n",
    "\n",
    "# Columns you want to study\n",
    "cols = []\n",
    "\n",
    "# Number of rows you want to include\n",
    "nrows = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "df = pd.read_csv(\n",
    "    path,\n",
    "\n",
    "    # Uncomment the following lines as needed\n",
    "\n",
    "    usecols = cols,\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\";\",\n",
    "    lineterminator=\"\\n\",\n",
    "    header=0,\n",
    "\n",
    "    # The following is useful if your dataset is large and you wish to test this notebook.\n",
    "    nrows=nrows\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The identifier fields\n",
    "id_cols = []\n",
    "# The numerical columns\n",
    "num_cols = []\n",
    "# The categorical columns\n",
    "cat_cols = []\n",
    "# The date columns\n",
    "dat_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete missing values and columns\n",
    "\n",
    "# Add fields to the columns_to_drop argument if needed\n",
    "columns_to_drop = []\n",
    "df = drop(df, columns_to_drop)\n",
    "\n",
    "# Choose the target column name\n",
    "target = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "clean(df, id_cols= id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data\n",
    "\n",
    "explo(df, cat_cols, dat_cols, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = []\n",
    "\n",
    "combines = col_set(cat_cols)\n",
    "combines_2 = [x for x in combines if len(x) == 2]\n",
    "\n",
    "for x,y in combines_2:\n",
    "    u, v = categorical_comparison(df, x, y)\n",
    "    pvals.append(u)\n",
    "    print(\"The p-value of the chi2 test between {} and {} is {}\".format(x, y, u))\n",
    "    #v.plot.bar(figsize=(7,4), rot=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_correlation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose target variables\n",
    "\n",
    "target_variables =list(df.columns)\n",
    "\n",
    "# The aggregation will be made with k = .1% of the dataset size\n",
    "\n",
    "n_1_perc = int((len(df)*0.001)//1)\n",
    "print(n_1_perc)\n",
    "\n",
    "SA = [target]\n",
    "QI = target_variables.copy()\n",
    "QI.remove(target)\n",
    "\n",
    "# Create df copy\n",
    "\n",
    "cols_df = df[target_variables].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of validation set\n",
    "\n",
    "val_set = cols_df.sample(frac=0.05)\n",
    "\n",
    "cols_df.drop(index = val_set.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local aggregation on categorical columns\n",
    "\n",
    "from utils.ano_correc import all_local_aggregation, get_diversities, less_diverse_groups, get_l\n",
    "\n",
    "ano_df = all_local_aggregation(cols_df.copy(),k=n_1_perc, variables = target_variables, method = 'regroup_with_smallest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise addition on numerical columns\n",
    "\n",
    "from utils.perturbation import numerical_perturbation\n",
    "\n",
    "ano_df = numerical_perturbation(ano_df, num_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protection des outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The minimal number of duplicated attributes allowed to not be considered as an outlier\n",
    "\n",
    "n = n_1_perc//10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des outliers en terme de donnée catégorielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = identify_outliers(ano_df, target, cat_cols, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [list(u.index.values) for u in dic.values()]\n",
    "to_remove = [set(u) for u in to_remove]\n",
    "to_remove = set().union(*to_remove)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des outliers en terme de donnée numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_num_outliers(cols_df, num_cols, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitement des outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By definition, outliers are a threat to non individualization : we can delete them\n",
    "\n",
    "cols_df.drop(index = to_remove, inplace=True)\n",
    "ano_df.drop(index=to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the three datasets\n",
    "\n",
    "cols_df.to_csv(\"data/ori.csv\")\n",
    "val_set.to_csv(\"data/control.csv\")\n",
    "ano_df.to_csv(\"data/ano.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An estimate on time spent anonymizing the dataset\n",
    "\n",
    "t1 = time.time()\n",
    "elapsed_time = t1-t0\n",
    "print(\"The computational time for {} rows is {}\".format(nrows, elapsed_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
