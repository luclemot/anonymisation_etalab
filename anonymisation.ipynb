{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymisation du jeu de données des équidés"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "# Classic modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Anonymization modules\n",
    "from anonymizer.anonymity import get_k\n",
    "from anonymizer.anonymity import local_aggregation\n",
    "\n",
    "#from anonympy.pandas import dfAnonymizer\n",
    "\n",
    "from pycanon import anonymity, report\n",
    "\n",
    "# Functions\n",
    "from utils.exploration import explo, clean, drop\n",
    "from utils.correlation import categorical_comparison, p_vals_correction, numerical_correlation\n",
    "from utils.tools import col_set\n",
    "from utils.outliers import identify_outliers, explore_outliers, identify_num_outliers, cluster\n",
    "from utils.stats import info_loss, categorical_loss, numerical_loss, plot_info_loss\n",
    "from utils.inference import Infer_Model, compare_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your dataset\n",
    "path = \"\"\n",
    "\n",
    "# Columns you want to study\n",
    "cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "df = pd.read_csv(\n",
    "    path,\n",
    "    usecols = cols,\n",
    "\n",
    "    # Uncomment the following lines as needed\n",
    "\n",
    "    #encoding=\"utf-8\",\n",
    "    #sep=\",\",\n",
    "    #lineterminator=\"\\n\",\n",
    "    #header=0,\n",
    "\n",
    "    # The following is useful if your dataset is large and you wish to test this notebook.\n",
    "    #nrows=100000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The identifier fields\n",
    "id_cols = []\n",
    "# The numerical columns\n",
    "num_cols = []\n",
    "# The categorical columns\n",
    "cat_cols = []\n",
    "# The date columns\n",
    "dat_cols = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "clean(df, id_cols= id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data\n",
    "\n",
    "explo(df, cat_cols, dat_cols, num_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete missing values and columns\n",
    "\n",
    "# Add fields to the columns_to_drop argument if needed\n",
    "columns_to_drop = []\n",
    "drop(df, columns_to_drop)\n",
    "\n",
    "# Choose the target column name\n",
    "target = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = []\n",
    "\n",
    "combines = col_set(cat_cols)\n",
    "combines_2 = [x for x in combines if len(x) == 2]\n",
    "\n",
    "for x,y in combines_2:\n",
    "    u, v = categorical_comparison(df, x, y)\n",
    "    pvals.append(u)\n",
    "    print(\"The p-value of the chi2 test between {} and {} is {}\".format(x, y, u))\n",
    "    #v.plot.bar(figsize=(7,4), rot=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_correlation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose target variables\n",
    "\n",
    "target_variables =list(df.columns)\n",
    "\n",
    "n_1_perc = int((len(df)*0.001)//1)\n",
    "print(n_1_perc)\n",
    "\n",
    "SA = [target]\n",
    "QI = target_variables.copy()\n",
    "QI.remove(target)\n",
    "\n",
    "# Create df copy\n",
    "\n",
    "cols_df = df[target_variables].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of validation set\n",
    "\n",
    "val_set = cols_df.sample(frac=0.05)\n",
    "\n",
    "cols_df.drop(index = val_set.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ano_correc import all_local_aggregation, get_diversities, less_diverse_groups, get_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_df = all_local_aggregation(cols_df.copy(),k=n_1_perc, variables = target_variables, method = 'regroup_with_smallest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(ano_df.columns)\n",
    "for x in cols :\n",
    "    QI = list(ano_df.columns)\n",
    "    QI.remove(x)\n",
    "    n = np.mean(ano_df.groupby(QI)[x].count())\n",
    "    l = get_l(ano_df, QI, x)\n",
    "    print(\"For {} as QIs and {} as the target, the l-diversity is of {} throughout {} values on average.\".format(QI, x, l, n))\n",
    "    trial = get_diversities(ano_df, QI, x)\n",
    "    #print(trial.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche adverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ano_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate k for k-anonymity:\n",
    "#k = anonymity.k_anonymity(temp, QI)\n",
    "\n",
    "#print(\"According to the anonymity pycanon module, the k-anonymity is {}\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the anonymity report:\n",
    "temp.reset_index(inplace=True, drop=True)\n",
    "report.print_report(temp, QI, SA)\n",
    "\n",
    "# Analyze results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non individualisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers\n",
    "\n",
    "temp.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des outliers en terme de donnée catégorielle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raisonnement suivi :  \\\n",
    "Pour chaque combinaison de colonnes, on regarde le compte de chevaux qui ont la même combinaison de ces variables.\\\n",
    "Si il y a moins de n individus pour une même combinaison, on la stocke dans outliers.\\\n",
    "On ajoute ce dataframe à un dictionnaire qui a pour clé le nom des colonnes dont il est question.\\\n",
    "\\\n",
    "Limites de cette méthode :\n",
    "- On n'a pas de méthode prédéfinie d'analyse de ces outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il faudrait déterminer une méthodologie : étant donnée la taille totale du jeu, comment choisir une valeur de n acceptable?\n",
    "# Ici, 10 pour n = 10 000 : on est sur 0.0001\n",
    "n = 10\n",
    "cat_cols = temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = identify_outliers(temp, target, cat_cols, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [list(u.index.values) for u in dic.values()]\n",
    "to_remove = [set(u) for u in to_remove]\n",
    "to_remove = set().union(*to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore_outliers(df, {\"RACE\": \"SELLE ETRANGER\", \"PAYS_DE_NAISSANCE\":\"PAYS-BAS\", \"ROBE\":\"NOIR PANGARE\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regarder PCA projetée en 2D et regarder un plot\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "X = enc.fit_transform(temp[QI]).toarray()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "res = pd.DataFrame(pca.fit_transform(X),columns=['PC1','PC2']) \n",
    "\n",
    "plt.scatter(res['PC1'], res['PC2'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des outliers en terme de donnée numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use identify_num_outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des doubles outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster analysis\n",
    "\n",
    "# cluster(temp, n_clusters = 100, cat_cols = cat_cols)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitement des outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers s'opposent à la non individualisation : on a le droit d'écarter la donnée\n",
    "\n",
    "cols_df.drop(index = to_remove, inplace=True)\n",
    "temp.drop(index=to_remove, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non inférence :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier scénario d'attaque : prédire un attribut d'un individu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer l'inférence pour toutes les répartitions de variables\n",
    "\n",
    "res = pd.DataFrame(columns = [\"Target\", \"Score de performance de la prédiction\", \"Delta in score\"])\n",
    "\n",
    "for x in temp.columns :\n",
    "    target = x \n",
    "    QI = list(temp.columns)\n",
    "    QI.remove(target)\n",
    "    model = Infer_Model(temp, cat_cols=QI, num_cols = [], target = target)\n",
    "    before_model = Infer_Model(cols_df, cat_cols=QI, num_cols = [], target = target)\n",
    "    model.prep_data()\n",
    "    before_model.prep_data()\n",
    "    model.df = model.df.align(before_model.df, join='right', axis=1, fill_value=0)[0]\n",
    "\n",
    "    x_train, x_test, y_train, y_test =  model.split()\n",
    "    pred = model.train_model(x_train, x_test, y_train, y_test)\n",
    "    x_train, x_test, y_train, y_test =  before_model.split()\n",
    "    pred_original = before_model.train_model(x_train, x_test, y_train, y_test)\n",
    "    val_model = Infer_Model(val_set, cat_cols=QI, num_cols = [], target = target)\n",
    "    val_model.prep_data()\n",
    "    val_model.df = val_model.df.align(before_model.df, join='right', axis=1, fill_value=0)[0]\n",
    "    new_cols =list(val_model.df.columns)\n",
    "    new_cols.remove(target)\n",
    "    _, model_score, delta = compare_models(pred, pred_original, val_model.df[new_cols], val_model.df[target], print=False)\n",
    "    res.loc[len(res)] = [target, model_score, delta]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.plot.bar(x='Target', stacked=True, color=['tomato','lightseagreen'], figsize=(7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_info_loss(df, temp, cat_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième scénario d'attaque : ré-entrainer un modèle en connaissant un certain nombre de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on train sur un sous-jeu\n",
    "attack_df = df[target_variables].copy()\n",
    "\n",
    "attacker_set = attack_df.sample(frac=0.3)\n",
    "attack_df.drop(index = attacker_set.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On entraine le modèle\n",
    "attack_model = Infer_Model(attacker_set, cat_cols=QI, num_cols = [], target = target)\n",
    "attack_model.prep_data()\n",
    "x_train, x_test, y_train, y_test =  attack_model.split()\n",
    "attack_pred = attack_model.train_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on teste sur la donnée anonymisée et sur la donnée normale et on voit si on sous-performe maintenant\n",
    "attacker_ano = all_local_aggregation(attack_df.copy(),k=n_1_perc, variables = QI, method = 'regroup_with_smallest')\n",
    "\n",
    "for x in [attacker_ano, attack_df]:\n",
    "    val_model = Infer_Model(x, cat_cols=QI, num_cols = [], target = target)\n",
    "    val_model.prep_data()\n",
    "    val_model.df = val_model.df.align(attack_model.df, join='right', axis=1, fill_value=0)[0]\n",
    "    new_cols =list(val_model.df.columns)\n",
    "    new_cols.remove(target)\n",
    "    print(attack_pred.score(val_model.df[new_cols], val_model.df[target]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité de la donnée statistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perte d'information - donnée catégorielle\n",
    "info_loss(df, temp, QI)\n",
    "\n",
    "# Rajouter info loss sur la variable target parce que c'est ça l'idée au fond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rajouter comparaison sur donnée numérique (moyenne, écart type, par colonne, corrélations?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
